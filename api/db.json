{
    "models": [
      {
        "id": 1,
        "name": "codellama-13b-oasst-sft-v10",
        "category": "Advanced Text Generation",
        "image": "/1.jpeg",
        "provider": "Hugging Face",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"codellama-13b-oasst-sft-v10\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "A text generation model designed for various text generation tasks. It utilizes a 13-billion parameter architecture optimized for OpenAI's Semantic Text Formatting (OASST) framework, version 10."
      },
      {
        "id": 2,
        "name": "falcon-40b-megacode2-oasst",
        "category": "Software Development AI",
        "image": "/2.jpeg",
        "provider": "Open Assistant",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"falcon-40b-megacode2-oasst\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "Leveraging a robust 40-billion parameter architecture, this text generation model is specialized for MegaCode2 tasks and integrates seamlessly with OpenAI's Semantic Text Formatting (OASST)."
      },
      {
        "id": 3,
        "name": "pythia-12b-sft-v8-rlhf-2k-steps",
        "category": "Text Generation",
        "image": "/3.jpeg",
        "provider": "OpenAI",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"pythia-12b-sft-v8-rlhf-2k-steps\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "A text generation model with a 12-billion parameter architecture optimized for OpenAI's Semantic Text Formatting (SFT) version 8. It features reinforcement learning fine-tuning over 2,000 steps."
      },
      {
        "id": 4,
        "name": "Wizard v1.1",
        "category": "Enterprise AI Solutions",
        "image": "/4.jpeg",
        "provider": "Hugging Face",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"Wizard-v1.1\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "Renowned as the best overall model, Wizard v1.1 is an instruction-based text generation model. It produces lengthy responses and has been fine-tuned with a limited but high-quality dataset."
      },
      {
        "id": 5,
        "name": "GPT4All Falcon",
        "category": "Semantic Text Processing",
        "image": "/5.jpeg",
        "provider": "Open Assistant",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"GPT4All-Falcon\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "Recognized as the best overall smaller model, Falcon is an instruction-based text generation model known for its swift responses. It's trained by TII and fine-tuned by Nomic AI."
      },
      {
        "id": 6,
        "name": "Hermes",
        "category": "Contextual AI Solutions",
        "image": "/6.jpeg",
        "provider": "OpenAI",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"Hermes\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "A proficient text generation model, Hermes operates on instructions and delivers extensive responses. It's curated with 300,000 uncensored instructions and trained by Nous Research. "
      },
      {
        "id": 7,
        "name": "Snoozy",
        "category": "AI Assistants",
        "image": "/7.jpeg",
        "provider": "Open Assistant",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"Snozzy\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "A highly capable text generation model, Snoozy operates on instructions and provides responses of superior quality. It's based on Groovy but offers higher quality responses."
      },
      {
        "id": 8,
        "name": "Mini",
        "category": "Conversational AI",
        "image": "/8.jpeg",
        "provider": "Hugging Face",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"Mini\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "New model with novel dataset. Instruction based. Explain tuned datasets. Orca Research Paper dataset construction approaches. Licensed for commercial use."
      },
      {
        "id": 9,
        "name": "Orca ",
        "category": "Enterprise AI Solutions",
        "image": "/9.jpeg",
        "provider": "Open Assistant",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"Orca\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "The largest version of the Mini Orca model, equipped with a robust architecture and the same novel dataset and instruction-based approach."
      },
      {
        "id": 10,
        "name": "Wizard Uncensored",
        "category": "Privacy-Focused AI",
        "image": "/10.jpeg",
        "provider": "OpenAI",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"Wizard-Uncensored\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "Trained on uncensored assistant data and instruction data, Wizard Uncensored is an instruction-based text generation model. "
      },
      {
        "id": 11,
        "name": "Replit",
        "category": "Developer Tools",
        "image": "/11.jpeg",
        "provider": "Hugging Face",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"Replit\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "Trained on a subset of the Stack, Replit is a code completion-based text generation model. It's licensed for commercial use."
      },
      {
        "id": 12,
        "name": "Bert",
        "category": "Natural Language Processing",
        "image": "/12.jpeg",
        "provider": "Open Assistant",
        "code": "from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\n\n# Load tokenizer and model\ntokenizer = AutoTokenizer.from_pretrained(\"Bert\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"codellama-13b-oasst-sft-v10\")\n\n# Example text\ntext = \"This is an example sentence.\"\n\n# Tokenize input text\ninputs = tokenizer(text, return_tensors=\"pt\")\n\n# Forward pass through the model\noutputs = model(**inputs)\n\n# Get prediction\npredicted_class_idx = torch.argmax(outputs.logits)\npredicted_class = model.config.id2label[predicted_class_idx.item()]\n\nprint(\"Predicted class:\", predicted_class)",
        "details": "A model primarily designed for generating embeddings, which are representations of text suitable for various natural language processing tasks."
      }
    ]
}
  